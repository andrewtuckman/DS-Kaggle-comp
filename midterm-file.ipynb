{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS506 Midterm\n",
    "### Name: Andrew Tuckman\n",
    "### BUID: U40643751"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files into DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['Score','Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Score                                               Text\n",
      "0          4.0  This is a charming version of the classic Dick...\n",
      "1          3.0  It was good but not as emotionally moving as t...\n",
      "2          3.0  Don't get me wrong, Winkler is a wonderful cha...\n",
      "3          5.0  Henry Winkler is very good in this twist on th...\n",
      "4          4.0  This is one of the best Scrooge movies out.  H...\n",
      "...        ...                                                ...\n",
      "1697528    NaN  wow $269.99 for the entire series on Blu Ray??...\n",
      "1697529    5.0  Finally, the holy grail of tv-on-dvd boxsets i...\n",
      "1697530    5.0  Could this be a true or I'm i dreaming batman ...\n",
      "1697531    5.0  I've been a fan of the series since I was a yo...\n",
      "1697532    5.0  People seriously need to wake up and realize t...\n",
      "\n",
      "[1697533 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Score                                               Text\n",
      "0          4.0  This is a charming version of the classic Dick...\n",
      "1          3.0  It was good but not as emotionally moving as t...\n",
      "2          3.0  Don't get me wrong, Winkler is a wonderful cha...\n",
      "3          5.0  Henry Winkler is very good in this twist on th...\n",
      "4          4.0  This is one of the best Scrooge movies out.  H...\n",
      "...        ...                                                ...\n",
      "1697526    4.0  Looking very much forward to this release, but...\n",
      "1697529    5.0  Finally, the holy grail of tv-on-dvd boxsets i...\n",
      "1697530    5.0  Could this be a true or I'm i dreaming batman ...\n",
      "1697531    5.0  I've been a fan of the series since I was a yo...\n",
      "1697532    5.0  People seriously need to wake up and realize t...\n",
      "\n",
      "[1397480 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Text Pre-processing -\n",
    "###  Remove characters from strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "expr_pattern = re.compile(pattern = r\"[\\W\\S]+\", flags = 0)\n",
    "train['Text'] = [expr_pattern.sub('', word) for word in train['Text'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert string sentences to list of lowercase string words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Text'] = train['Text'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Score                                               Text\n",
      "0          4.0  [this, is, a, charming, version, of, the, clas...\n",
      "1          3.0  [it, was, good, but, not, as, emotionally, mov...\n",
      "2          3.0  [dont, get, me, wrong, winkler, is, a, wonderf...\n",
      "3          5.0  [henry, winkler, is, very, good, in, this, twi...\n",
      "4          4.0  [this, is, one, of, the, best, scrooge, movies...\n",
      "...        ...                                                ...\n",
      "1697526    4.0  [looking, very, much, forward, to, this, relea...\n",
      "1697529    5.0  [finally, the, holy, grail, of, tvondvd, boxse...\n",
      "1697530    5.0  [could, this, be, a, true, or, im, i, dreaming...\n",
      "1697531    5.0  [ive, been, a, fan, of, the, series, since, i,...\n",
      "1697532    5.0  [people, seriously, need, to, wake, up, and, r...\n",
      "\n",
      "[1397480 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = ['i', \"i've\", \"ive\", 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"youre\", \"you've\", \"youve\", \"you'll\", \"you'd\", \"youll\", \"youd\", 'your', 'yours', 'yourself', \n",
    "'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", \"shes\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', \n",
    "'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", \"thatll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', \n",
    "'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', \n",
    "'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', \n",
    "'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", \"dont\", 'should', \"should've\", \"shouldve\",\n",
    "'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", \"arent\", 'couldn', \"couldn't\", \"couldnt\", 'didn', \"didn't\", \"didnt\", 'doesn', \"doesn't\", \"doesnt\", 'hadn', \"hadn't\", \"hadnt\", 'hasn', \n",
    "\"hasn't\", \"hasnt\", 'haven', \"haven't\", \"havent\", 'isn', \"isn't\", \"isnt\", 'ma', 'mightn', \"mightn't\", \"mightnt\", 'mustn', \"mustn't\", \"mustnt\", 'needn', \"needn't\", \"neednt\", 'shan', \"shan't\", \"shant\", 'shouldn', \"shouldn't\", \"shouldnt\", \n",
    "'wasn', \"wasn't\", \"wasnt\", 'weren', \"weren't\", \"werent\", 'won', \"won't\", \"wont\", 'wouldn', \"wouldn't\", \"wouldnt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Text'] = train['Text'].apply(lambda review: [word for word in review if word not in stopwords_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Score                                               Text\n",
      "0          4.0  [this, is, a, charming, version, of, the, clas...\n",
      "1          3.0  [it, was, good, but, not, as, emotionally, mov...\n",
      "2          3.0  [dont, get, me, wrong, winkler, is, a, wonderf...\n",
      "3          5.0  [henry, winkler, is, very, good, in, this, twi...\n",
      "4          4.0  [this, is, one, of, the, best, scrooge, movies...\n",
      "...        ...                                                ...\n",
      "1697526    4.0  [looking, very, much, forward, to, this, relea...\n",
      "1697529    5.0  [finally, the, holy, grail, of, tvondvd, boxse...\n",
      "1697530    5.0  [could, this, be, a, true, or, im, i, dreaming...\n",
      "1697531    5.0  [ive, been, a, fan, of, the, series, since, i,...\n",
      "1697532    5.0  [people, seriously, need, to, wake, up, and, r...\n",
      "\n",
      "[1397480 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert lists back into strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Text'] = train['Text'].apply(', '.join)\n",
    "expr_pattern1 = re.compile(pattern = r\"[\\W\\S]+\", flags = 0)\n",
    "train['Text'] = [expr_pattern1.sub('', x) for x in train['Text'].tolist()]\n",
    "train['Text'] = train['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Score                                               Text\n",
      "0          4.0  this is a charming version of the classic dick...\n",
      "1          3.0  it was good but not as emotionally moving as t...\n",
      "2          3.0  dont get me wrong winkler is a wonderful chara...\n",
      "3          5.0  henry winkler is very good in this twist on th...\n",
      "4          4.0  this is one of the best scrooge movies out hen...\n",
      "...        ...                                                ...\n",
      "1697526    4.0  looking very much forward to this release but ...\n",
      "1697529    5.0  finally the holy grail of tvondvd boxsets is c...\n",
      "1697530    5.0  could this be a true or im i dreaming batman i...\n",
      "1697531    5.0  ive been a fan of the series since i was a you...\n",
      "1697532    5.0  people seriously need to wake up and realize t...\n",
      "\n",
      "[1397480 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Fit data -\n",
    "\n",
    "### Extract two columns of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['Text']\n",
    "y_train = train['Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the review column 'Text':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X_train_vectorized = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit training data using Linear Support Vector Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LinearSVC(dual = False, C = 0.5)\n",
    "# clf.fit(X = X_train_vectorized, y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a Pipeline to perform Vectorization and Classifier together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf', LinearSVC(C=0.5, dual=False))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = Pipeline(steps = [('tfidfvectorizer', TfidfVectorizer()), ('linearsvc', LinearSVC(dual = False, C = 0.2))])\n",
    "clf.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing test file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id  Score\n",
      "0             5    NaN\n",
      "1            11    NaN\n",
      "2            17    NaN\n",
      "3            46    NaN\n",
      "4            47    NaN\n",
      "...         ...    ...\n",
      "299995  1697520    NaN\n",
      "299996  1697522    NaN\n",
      "299997  1697524    NaN\n",
      "299998  1697527    NaN\n",
      "299999  1697528    NaN\n",
      "\n",
      "[300000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.read_csv(\"./data/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
      "0              0  0005019281   ADZPIG9QOCDG5                     0   \n",
      "1              1  0005019281  A35947ZP82G7JH                     0   \n",
      "2              2  0005019281  A3UORV8A9D5L2E                     0   \n",
      "3              3  0005019281  A1VKW06X1O2X7V                     0   \n",
      "4              4  0005019281  A3R27T4HADWFFJ                     0   \n",
      "...          ...         ...             ...                   ...   \n",
      "1697528  1697528  B00LT1JHLW   AV657BUYHHXZ2                     1   \n",
      "1697529  1697529  B00LT1JHLW  A17W587EH23J0Q                    32   \n",
      "1697530  1697530  B00LT1JHLW  A3DE438TF1A958                     3   \n",
      "1697531  1697531  B00LT1JHLW  A2RWCXDMANY0LW                     0   \n",
      "1697532  1697532  B00LT1JHLW  A3ROPC55BE2OM9                    11   \n",
      "\n",
      "         HelpfulnessDenominator  Score        Time  \\\n",
      "0                             0    4.0  1203984000   \n",
      "1                             0    3.0  1388361600   \n",
      "2                             0    3.0  1388361600   \n",
      "3                             0    5.0  1202860800   \n",
      "4                             0    4.0  1387670400   \n",
      "...                         ...    ...         ...   \n",
      "1697528                      14    NaN  1406073600   \n",
      "1697529                      48    5.0  1405641600   \n",
      "1697530                      10    5.0  1405728000   \n",
      "1697531                       4    5.0  1405987200   \n",
      "1697532                      23    5.0  1405728000   \n",
      "\n",
      "                                                   Summary  \\\n",
      "0                                good version of a classic   \n",
      "1                                   Good but not as moving   \n",
      "2                    Winkler's Performance was ok at best!   \n",
      "3             It's an enjoyable twist on the classic story   \n",
      "4                                         Best Scrooge yet   \n",
      "...                                                    ...   \n",
      "1697528                      Way to Expensive!! WB = GREED   \n",
      "1697529  HOLY BAT-BOXSET, BATMAN... I never thought thi...   \n",
      "1697530  prayers have been answered because batman 60s ...   \n",
      "1697531                                        can't Wait!   \n",
      "1697532  The Price is Insane? People Really Need to Wak...   \n",
      "\n",
      "                                                      Text  \n",
      "0        This is a charming version of the classic Dick...  \n",
      "1        It was good but not as emotionally moving as t...  \n",
      "2        Don't get me wrong, Winkler is a wonderful cha...  \n",
      "3        Henry Winkler is very good in this twist on th...  \n",
      "4        This is one of the best Scrooge movies out.  H...  \n",
      "...                                                    ...  \n",
      "1697528  wow $269.99 for the entire series on Blu Ray??...  \n",
      "1697529  Finally, the holy grail of tv-on-dvd boxsets i...  \n",
      "1697530  Could this be a true or I'm i dreaming batman ...  \n",
      "1697531  I've been a fan of the series since I was a yo...  \n",
      "1697532  People seriously need to wake up and realize t...  \n",
      "\n",
      "[1697533 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test.join(train2, on='Id', how = 'inner', lsuffix=' test_data', rsuffix=' train2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id  Id test_data  Score test_data  Id train2   ProductId  \\\n",
      "0             5             5              NaN          5  0005019281   \n",
      "1            11            11              NaN         11  0005019281   \n",
      "2            17            17              NaN         17  0005019281   \n",
      "3            46            46              NaN         46  0005019281   \n",
      "4            47            47              NaN         47  0005019281   \n",
      "...         ...           ...              ...        ...         ...   \n",
      "299995  1697520       1697520              NaN    1697520  B00LH9ROKM   \n",
      "299996  1697522       1697522              NaN    1697522  B00LT1JHLW   \n",
      "299997  1697524       1697524              NaN    1697524  B00LT1JHLW   \n",
      "299998  1697527       1697527              NaN    1697527  B00LT1JHLW   \n",
      "299999  1697528       1697528              NaN    1697528  B00LT1JHLW   \n",
      "\n",
      "                UserId  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
      "0       A2L0G56BNOTX6S                     0                       0   \n",
      "1       A33EWPXESP9GQH                     0                       0   \n",
      "2       A13KAQO9F5X0FN                     0                       0   \n",
      "3       A306NASGVUDFKF                    10                      14   \n",
      "4       A38G1NN5SD81GD                     0                       1   \n",
      "...                ...                   ...                     ...   \n",
      "299995   AYB0IXBPBJ20A                     0                       1   \n",
      "299996   AU73NIGESSIRE                    25                      88   \n",
      "299997  A3PPYOJBMFBP6U                     3                      10   \n",
      "299998  A2CA2Q6JS6CQAE                    10                      14   \n",
      "299999   AV657BUYHHXZ2                     1                      14   \n",
      "\n",
      "        Score train2        Time  \\\n",
      "0                NaN  1383696000   \n",
      "1                NaN  1390780800   \n",
      "2                NaN  1389657600   \n",
      "3                NaN  1132963200   \n",
      "4                NaN  1384905600   \n",
      "...              ...         ...   \n",
      "299995           NaN  1404345600   \n",
      "299996           NaN  1405555200   \n",
      "299997           NaN  1405728000   \n",
      "299998           NaN  1405987200   \n",
      "299999           NaN  1406073600   \n",
      "\n",
      "                                                  Summary  \\\n",
      "0                                        Dickens updated.   \n",
      "1                                            Good Version   \n",
      "2                                   the fonz does scrooge   \n",
      "3                 A refreshing twist on a Holiday classic   \n",
      "4                                         Not my favorite   \n",
      "...                                                   ...   \n",
      "299995  Basically an Episode of Criminal Minds, See It...   \n",
      "299996  July 17, 2014 - the first day of pre-order (wi...   \n",
      "299997  Please Include The 'Batman In Color' Bumper Wh...   \n",
      "299998    Finally on dvd and blu-ray The Batman TV Series   \n",
      "299999                      Way to Expensive!! WB = GREED   \n",
      "\n",
      "                                                     Text  \n",
      "0       This has been a favorite movie of mine for a l...  \n",
      "1       Even though i don't care for Henry Winklers  a...  \n",
      "2       Anorher good movie for holiday watchers..a lit...  \n",
      "3       My wife and I grew up in New Hampshire where t...  \n",
      "4       This is a first for me, I didn't like this mov...  \n",
      "...                                                   ...  \n",
      "299995  Just how seriously one should take Scott Derri...  \n",
      "299996  Let's be clear - the 5 stars are for the serie...  \n",
      "299997  I would also like to see the original 20th Cen...  \n",
      "299998  Finally to be released on DVD and Blu-Ray Nove...  \n",
      "299999  wow $269.99 for the entire series on Blu Ray??...  \n",
      "\n",
      "[300000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting usable columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_extract = test2[['Id','Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id                                               Text\n",
      "0             5  This has been a favorite movie of mine for a l...\n",
      "1            11  Even though i don't care for Henry Winklers  a...\n",
      "2            17  Anorher good movie for holiday watchers..a lit...\n",
      "3            46  My wife and I grew up in New Hampshire where t...\n",
      "4            47  This is a first for me, I didn't like this mov...\n",
      "...         ...                                                ...\n",
      "299995  1697520  Just how seriously one should take Scott Derri...\n",
      "299996  1697522  Let's be clear - the 5 stars are for the serie...\n",
      "299997  1697524  I would also like to see the original 20th Cen...\n",
      "299998  1697527  Finally to be released on DVD and Blu-Ray Nove...\n",
      "299999  1697528  wow $269.99 for the entire series on Blu Ray??...\n",
      "\n",
      "[300000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test2_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_extract = test2_extract .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id                                               Text\n",
      "0             5  This has been a favorite movie of mine for a l...\n",
      "1            11  Even though i don't care for Henry Winklers  a...\n",
      "2            17  Anorher good movie for holiday watchers..a lit...\n",
      "3            46  My wife and I grew up in New Hampshire where t...\n",
      "4            47  This is a first for me, I didn't like this mov...\n",
      "...         ...                                                ...\n",
      "299995  1697520  Just how seriously one should take Scott Derri...\n",
      "299996  1697522  Let's be clear - the 5 stars are for the serie...\n",
      "299997  1697524  I would also like to see the original 20th Cen...\n",
      "299998  1697527  Finally to be released on DVD and Blu-Ray Nove...\n",
      "299999  1697528  wow $269.99 for the entire series on Blu Ray??...\n",
      "\n",
      "[299991 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test2_extract) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Text pre-processing - (Same as before)\n",
    "### Remove characters from strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_pattern2 = re.compile(pattern = r\"[\\W\\S]+\", flags = 0)\n",
    "test2_extract['Text'] = [expr_pattern2.sub('', x) for x in test2_extract['Text'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id Text\n",
      "0             5     \n",
      "1            11     \n",
      "2            17     \n",
      "3            46     \n",
      "4            47     \n",
      "...         ...  ...\n",
      "299995  1697520     \n",
      "299996  1697522     \n",
      "299997  1697524     \n",
      "299998  1697527     \n",
      "299999  1697528     \n",
      "\n",
      "[299991 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test2_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert string sentences to list of lowercase string words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_extract['Text'] = test2_extract['Text'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id Text\n",
      "0             5   []\n",
      "1            11   []\n",
      "2            17   []\n",
      "3            46   []\n",
      "4            47   []\n",
      "...         ...  ...\n",
      "299995  1697520   []\n",
      "299996  1697522   []\n",
      "299997  1697524   []\n",
      "299998  1697527   []\n",
      "299999  1697528   []\n",
      "\n",
      "[299991 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test2_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_extract['Text'] = test2_extract['Text'].apply(lambda review: [word for word in review if word not in stopwords_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id Text\n",
      "0             5   []\n",
      "1            11   []\n",
      "2            17   []\n",
      "3            46   []\n",
      "4            47   []\n",
      "...         ...  ...\n",
      "299995  1697520   []\n",
      "299996  1697522   []\n",
      "299997  1697524   []\n",
      "299998  1697527   []\n",
      "299999  1697528   []\n",
      "\n",
      "[299991 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test2_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert lists back into strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_extract['Text'] = test2_extract['Text'].apply(', '.join)\n",
    "expr_pattern3 = re.compile(pattern = r\"[\\W\\S]+\", flags = 0)\n",
    "test2_extract['Text'] = [expr_pattern3.sub('', x) for x in test2_extract['Text'].tolist()]\n",
    "test2_extract['Text'] = test2_extract['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id Text\n",
      "0             5     \n",
      "1            11     \n",
      "2            17     \n",
      "3            46     \n",
      "4            47     \n",
      "...         ...  ...\n",
      "299995  1697520     \n",
      "299996  1697522     \n",
      "299997  1697524     \n",
      "299998  1697527     \n",
      "299999  1697528     \n",
      "\n",
      "[299991 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test2_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract two columns of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = test2_extract['Text']\n",
    "y_test2 = test2_extract['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer2 = TfidfVectorizer()\n",
    "# X_test2_vectorized = vectorizer2.fit_transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test2.Text = X_test2_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing submission DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id' : test2_extract['Id'], 'Score' : predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id  Score\n",
      "0             5    5.0\n",
      "1            11    5.0\n",
      "2            17    5.0\n",
      "3            46    5.0\n",
      "4            47    5.0\n",
      "...         ...    ...\n",
      "299995  1697520    5.0\n",
      "299996  1697522    5.0\n",
      "299997  1697524    5.0\n",
      "299998  1697527    5.0\n",
      "299999  1697528    5.0\n",
      "\n",
      "[299991 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = test2.merge(submission, on = ['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = test2[(~test2['Id'].isin(final['Id']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract columns needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[['Id', 'Score test_data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id  Score test_data\n",
      "18795    106563              NaN\n",
      "43189    245184              NaN\n",
      "153210   864850              NaN\n",
      "180980  1022346              NaN\n",
      "191684  1082487              NaN\n",
      "197635  1116131              NaN\n",
      "220075  1243416              NaN\n",
      "221862  1253440              NaN\n",
      "281151  1589648              NaN\n"
     ]
    }
   ],
   "source": [
    "print(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.rename(columns = {'Score test_data' : 'Score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.append(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling null values with mean score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Score'].fillna(value = (submission['Score'].mean()), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to .csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path_or_buf = './data/my_submission3.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
